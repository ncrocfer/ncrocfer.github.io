<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Celery : l&#39;importance du pool d&#39;exécution &middot; Nicolas Crocfer</title>

    <meta name="description" content="">

    <meta name="generator" content="Hugo 0.42.2" />
    <meta name="twitter:card" content="summary">
    
    <meta name="twitter:title" content="Celery : l&#39;importance du pool d&#39;exécution &middot; Nicolas Crocfer">
    <meta name="twitter:description" content="">

    <meta property="og:type" content="article">
    <meta property="og:title" content="Celery : l&#39;importance du pool d&#39;exécution &middot; Nicolas Crocfer">
    <meta property="og:description" content="">

    <link href='//fonts.googleapis.com/css?family=Source+Sans+Pro:400,700|Oxygen:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.6.0/pure-min.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.6.0/grids-responsive-min.css">

    <link rel="stylesheet" href="https://ncrocfer.github.io/css/all.min.css">
    <link rel="stylesheet" href="https://ncrocfer.github.io/css/flexboxgrid.min.css">
    <link rel="stylesheet" href="https://ncrocfer.github.io/css/custom.css">
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet">

    <link rel="alternate" type="application/rss+xml" title="Nicolas Crocfer" href="https://ncrocfer.github.io/index.xml" />
</head>
<body>



<div id="layout" class="pure-g">
    <div class="sidebar pure-u-1 pure-u-md-1-4">
    <div class="header">
        <hgroup>
            <h1 class="brand-title"><a href="https://ncrocfer.github.io">Nicolas Crocfer</a></h1>
            <h2 class="brand-tagline"> Python Developer </h2>
        </hgroup>

        <nav class="nav">
            <ul class="nav-list">
                
                <li class="nav-item">
                    <a class="pure-button" href="https://twitter.com/ncrocfer">
                        <i class="fa fa-twitter"></i> Twitter
                    </a>
                </li>
                
                
                <li class="nav-item">
                    <a class="pure-button" href="https://github.com/ncrocfer">
                        <i class="fa fa-github-alt"></i> Github
                    </a>
                </li>
                
                
                
                <li class="nav-item">
                    <a class="pure-button" href="https://www.linkedin.com/in/nicolascrocfer">
                        <i class="fa fa-linkedin"></i> LinkedIn
                    </a>
                </li>
                
                <li class="nav-item">
                    <a class="pure-button" href="https://ncrocfer.github.io/index.xml">
                        <i class="fa fa-rss"></i> rss
                    </a>
                </li>
            </ul>
        </nav>
    </div>
</div>


    <div class="content pure-u-1 pure-u-md-3-4">
        <div>
            
            <div class="posts">
                <h1 class="content-subhead">12 Jan 2020, 13:25</h1>
                <section class="post">
                    <header class="post-header">

                        <a href="https://ncrocfer.github.io/posts/celery-importance-pool-execution/" class="post-title">Celery : l&#39;importance du pool d&#39;exécution</a>

                        <p class="post-meta">
                            
                            
                        </p>
                    </header>
                    
                    <div class="post-description">
                        

<p>En tant que dev nous sommes régulièrement amenés à devoir exécuter des tâches en arrière-plan. La plupart du temps il s&rsquo;agira de répondre à une action de l&rsquo;utilisateur (call d&rsquo;API, click sur un bouton&hellip;), parfois nous aurons besoin de lancer une tâche de manière périodique.</p>

<p>Dans les 2 cas l&rsquo;objectif est de ne pas bloquer le processus principal. En effet je vous laisse imaginer les pertes de performance si, au moment d&rsquo;un POST sur votre API, votre application se chargeait d&rsquo;exécuter elle-même une tâche lourde et très longue. L&rsquo;application rendrait la main à l&rsquo;utilisateur plusieurs secondes, voire plusieurs minutes, après le call.</p>

<img src="/images/celery.png" alt="" style="display: block; margin-left: auto; margin-right: auto; ">

<p>Pour répondre à ce besoin les dev Python ont pris l&rsquo;habitude d&rsquo;utiliser la librairie <strong>Celery</strong>. Cet article n&rsquo;est pas une introduction à cet outil, pour cela je vous renvoie vers le <a href="https://docs.celeryproject.org/en/latest/getting-started/first-steps-with-celery.html">quickstart</a> officiel, vous comprendrez rapidement à quoi il sert et surtout comment l&rsquo;utiliser.</p>

<p>Nous allons parler ici d&rsquo;une feature qui est parfois délaissée lorsqu&rsquo;on utilise Celery : les <strong>pools d&rsquo;exécution</strong>. Derrière cette notion se cache toute la magie de Celery : comment et par quoi mes tâches vont-elles s&rsquo;exécuter. Et vous allez voir que configurer correctement cette option peut amener des gains de performances incroyables !</p>

<h1 id="la-théorie">La théorie</h1>

<p>Lorsque nous lançons un worker Celery, nous lançons en fait un processus chargé de coordonner le lancement des tâches empilées dans le broker. En réalité leur exécution à proprement parler ne sera pas effectuée par ce processus mais par d&rsquo;autres processus enfants ou par des threads qu&rsquo;il aura lui-même spawné.</p>

<p>Et c&rsquo;est justement la façon dont est configuré le pool d&rsquo;éxécution qui détermine comment sont lancés ces processus ou threads capables d&rsquo;exécuter les tâches.</p>

<p>Celery fournit par défaut 4 pools d&rsquo;exécution : <strong>prefork</strong>, <strong>solo</strong>, <strong>gevent</strong> et <strong>eventlet</strong>. La configuration s&rsquo;effectue via l&rsquo;option <code>-P</code>.</p>

<h2 id="mode-prefork">Mode prefork</h2>

<p>Par défault le pool sélectionné par Celery est le prefork. Nous pouvons facilement le voir lorsque nous lançons un worker :</p>

<pre><code>$ celery -A tasks worker
celery@LAPTOP v4.4.0 (cliffs)

Darwin-17.7.0-x86_64-i386-64bit 2020-01-26 14:31:06

[config]
.&gt; app:         tasks:0x10566ca20
.&gt; transport:   redis://localhost:6379/0
.&gt; results:     disabled://
.&gt; concurrency: 4 (prefork)
.&gt; task events: OFF (enable -E to monitor tasks in this worker)

[queues]
.&gt; celery           exchange=celery(direct) key=celery
</code></pre>

<p>Ici la ligne <code>concurrency: 4 (prefork)</code> nous indique que nous utilisons le pool <code>prefork</code> avec une concurrency de <strong>4</strong>. Ce mode d&rsquo;exécution se base sur le package <a href="https://docs.python.org/fr/3/library/multiprocessing.html">multiprocessing</a> : Celery va donc spawner autant de processus que le nombre de coeurs de votre machine.</p>

<p>Nous pouvons vérifier que les processus ont bien été spawnés par Celery (le process principal et les 4 forks):</p>

<pre><code>$ ps -A | grep -i celery
91822 ttys000    0:01.59 /Users/ncrocfer/Dev/celery_pool/venv/bin/python3 /Users/ncrocfer/Dev/celery_pool/venv/bin/celery -A tasks worker
91828 ttys000    0:00.02 /Users/ncrocfer/Dev/celery_pool/venv/bin/python3 /Users/ncrocfer/Dev/celery_pool/venv/bin/celery -A tasks worker
91829 ttys000    0:00.02 /Users/ncrocfer/Dev/celery_pool/venv/bin/python3 /Users/ncrocfer/Dev/celery_pool/venv/bin/celery -A tasks worker
91830 ttys000    0:00.02 /Users/ncrocfer/Dev/celery_pool/venv/bin/python3 /Users/ncrocfer/Dev/celery_pool/venv/bin/celery -A tasks worker
91831 ttys000    0:00.02 /Users/ncrocfer/Dev/celery_pool/venv/bin/python3 /Users/ncrocfer/Dev/celery_pool/venv/bin/celery -A tasks worker
</code></pre>

<p>Ce mode est particulièrement adapté aux applications nécessitant du calcul par le CPU (ces applications sont dîtes <strong>CPU bound</strong>). Plus vous aurez de coeurs puissants et plus votre application pourra traiter de tâches en parallèle.</p>

<p>A noter que la concurrency est paramétrable via l&rsquo;option <code>-c</code> :</p>

<pre><code>$ celery -A tasks worker -c 2
...
.&gt; concurrency: 2 (prefork)
...
</code></pre>

<h2 id="mode-solo">Mode solo</h2>

<p>Ce mode est un peu particulier car le processus principal se chargera lui-même d&rsquo;exécuter les tâches qu&rsquo;il consommera :</p>

<pre><code>$ celery -A tasks worker -P solo
...
.&gt; concurrency: 4 (solo)
...
</code></pre>

<p>La concurrency reste à 4 mais ne vous y fiez pas, le mode <strong>solo</strong> ne s&rsquo;en encombre pas et n&rsquo;exécutera qu&rsquo;une seule tâche à la fois.</p>

<p>Là encore nous pouvons le vérifier via les processus en cours d&rsquo;exécution sur notre machine :</p>

<pre><code>$ ps -A | grep -i celery
92356 ttys000    0:01.13 /Users/ncrocfer/Dev/celery_pool/venv/bin/python3 /Users/ncrocfer/Dev/celery_pool/venv/bin/celery -A tasks worker -P solo
</code></pre>

<p>Hormis pour lancer des tests, ce mode pourra être utile dans le cas d&rsquo;un usage en environnement <em>containers</em>. En effet les comptes sont simples dans ce cas : <em>N</em> containers égal <em>N</em> tasks en parallèle.</p>

<h2 id="mode-gevent-eventlet">Mode gevent &amp; eventlet</h2>

<p>Là on arrive dans la partie intéressante :) A l&rsquo;inverse du mode <code>prefork</code> utile pour gérer des tâches <strong>CPU bound</strong>, ces deux modes vont nous permettre de gérer facilement les tâches dîtes <strong>IO bound</strong>.</p>

<p>De telles tâches n&rsquo;effectuent pas de calculs lourds, et ne nécessitent donc pas un grand nombre de CPU puissants. En revanche elles peuvent être amenées à effectuer beaucoup de requêtes vers d&rsquo;autres systèmes : une API externe, une base de données, un site web, etc. Ici notre CPU n&rsquo;a pas grand chose à faire puisque nos tâches vont principalement attendre le retour de leurs requêtes.</p>

<p>Je vous invite à vous renseigner sur la librairie <a href="https://docs.python.org/3/library/asyncio.html">Asyncio</a> qui expliquera tout ça mieux que moi.</p>

<p>Dans l&rsquo;exemple ci-dessous notre worker pourra gérer 100 tâches en parallèle via le mode <code>gevent</code> :</p>

<pre><code>$ celery -A tasks worker -P gevent -c 100
...
.&gt; concurrency: 100 (gevent)
...
</code></pre>

<h1 id="la-pratique">La pratique</h1>

<p>Trève de théorie, illustrons maintenant l&rsquo;utilisation des pool d&rsquo;exécution via un exemple.</p>

<p>Nous souhaitons lancer plusieurs tâches en parallèle effectuant une requête vers une API externe. Cette API renvoie un nombre au hasard, et une fonction de callback est appelée afin d&rsquo;effectuer la somme de ces nombres. Certes cet exemple est basique mais il va nous permettre de mettre en évidence la puissance des pools d&rsquo;exécution dans Celery.</p>

<p>L&rsquo;API tourne en locale, j&rsquo;ai utilisé <a href="https://sanic.readthedocs.io/en/latest/">Sanic</a> avec un timeout de 2 secondes <em>simulant</em> la latence d&rsquo;une API externe :</p>

<pre><code class="language-python">$ cat app.py
import random
import asyncio

from sanic import Sanic
from sanic.response import json


app = Sanic()


@app.get(&quot;/&quot;)
async def get_time(request):
    await asyncio.sleep(2)
    return json({&quot;number&quot;: random.randint(1, 10)})


if __name__ == &quot;__main__&quot;:
    app.run(host=&quot;0.0.0.0&quot;, port=8000)
</code></pre>

<p>Nos tâches sont elles-aussi très simples :</p>

<pre><code class="language-python">$ cat tasks.py
import requests
from celery import Celery, chord


app = Celery('tasks', broker='redis://localhost:6379/0', backend=&quot;redis://localhost:6379/1&quot;)


@app.task
def get_number():
    resp = requests.get(&quot;http://localhost:8000&quot;)
    return resp.json()[&quot;number&quot;]

@app.task
def sum_numbers(numbers):
    return sum(numbers)


sign = chord(
    [get_number.si() for _ in range(5)],
    sum_numbers.s()
)
</code></pre>

<p>J&rsquo;utilise un chord afin de lancer plusieurs requêtes en parallèle. La fonction <code>sum_numbers</code> est ensuite lancée afin de calculer la somme totale des nombres.</p>

<p>Le lancement peut s&rsquo;effectuer en une ligne :</p>

<pre><code>$ python -c &quot;from tasks import sign; sign.delay()&quot;
</code></pre>

<p>Testons avec le pool d&rsquo;exécution par défaut (prefork) :</p>

<pre><code>$ celery -A tasks worker --loglevel=INFO
...
[2020-01-26 19:30:48,852: INFO/MainProcess] Received task: tasks.get_number[5f2f8167-c667-4e83-b591-453e57b3a958]
[2020-01-26 19:30:48,855: INFO/MainProcess] Received task: tasks.get_number[a333586b-c396-4b91-917f-3fbdfa6d30e8]
[2020-01-26 19:30:48,860: INFO/MainProcess] Received task: tasks.get_number[88fa7cc0-2622-4053-8824-2f2d47c25a04]
[2020-01-26 19:30:48,876: INFO/MainProcess] Received task: tasks.get_number[fa35004e-51b8-4f48-ad84-e02640ed9621]
[2020-01-26 19:30:48,880: INFO/MainProcess] Received task: tasks.get_number[5ecb73c8-9ba5-4ebb-aaae-78e14908405a]
[2020-01-26 19:30:50,915: INFO/ForkPoolWorker-2] Task tasks.get_number[5f2f8167-c667-4e83-b591-453e57b3a958] succeeded in 2.057117607037071s: 1
[2020-01-26 19:30:50,915: INFO/ForkPoolWorker-3] Task tasks.get_number[a333586b-c396-4b91-917f-3fbdfa6d30e8] succeeded in 2.057576177001465s: 2
[2020-01-26 19:30:50,920: INFO/ForkPoolWorker-1] Task tasks.get_number[88fa7cc0-2622-4053-8824-2f2d47c25a04] succeeded in 2.0558868430089206s: 2
[2020-01-26 19:30:50,933: INFO/ForkPoolWorker-4] Task tasks.get_number[fa35004e-51b8-4f48-ad84-e02640ed9621] succeeded in 2.055466585967224s: 1
[2020-01-26 19:30:52,972: INFO/ForkPoolWorker-2] Task tasks.get_number[5ecb73c8-9ba5-4ebb-aaae-78e14908405a] succeeded in 2.0525691980146803s: 10
[2020-01-26 19:30:52,973: INFO/MainProcess] Received task: tasks.sum_numbers[605e4af4-229c-42a3-9be0-ce5daff79a0f]
[2020-01-26 19:30:52,975: INFO/ForkPoolWorker-2] Task tasks.sum_numbers[605e4af4-229c-42a3-9be0-ce5daff79a0f] succeeded in 0.0006177640170790255s: 16
</code></pre>

<p>Les tâches sont toutes prises en compte en une seule fois par notre worker (rien à voir avec la notion de pool d&rsquo;exécution, il s&rsquo;agit ici du <strong>prefetch</strong>, en gros le nombre de tâches qu&rsquo;un worker peut se <em>réserver</em>).</p>

<p>En revanche seules 4 tâches sont effectuées en même temps, il faudra attendre 2 secondes supplémentaires pour que la 5ème le soit également. Le workflow complet aura donc pris <strong>4 secondes</strong>.</p>

<p>Testons maintenant avec le pool d&rsquo;exécution <strong>gevent</strong> :</p>

<pre><code>$ celery -A tasks worker --loglevel=INFO -P gevent -c 100
...
[2020-01-26 19:35:12,151: INFO/MainProcess] Received task: tasks.get_number[04192b64-b71e-4e1c-8eb8-f86487c6b013]
[2020-01-26 19:35:12,163: INFO/MainProcess] Received task: tasks.get_number[12d227b5-f0b1-4fd8-8b44-25e8d8fbc028]
[2020-01-26 19:35:12,173: INFO/MainProcess] Received task: tasks.get_number[db7838f5-3543-414c-9816-7df62b13b65d]
[2020-01-26 19:35:12,182: INFO/MainProcess] Received task: tasks.get_number[52f163d4-7d75-493a-a3ac-65122691b078]
[2020-01-26 19:35:12,193: INFO/MainProcess] Received task: tasks.get_number[14537419-8710-4b32-bb13-6c884ff22dca]
[2020-01-26 19:35:14,202: INFO/MainProcess] Task tasks.get_number[04192b64-b71e-4e1c-8eb8-f86487c6b013] succeeded in 2.048632029967848s: 6
[2020-01-26 19:35:14,207: INFO/MainProcess] Task tasks.get_number[12d227b5-f0b1-4fd8-8b44-25e8d8fbc028] succeeded in 2.042411718983203s: 2
[2020-01-26 19:35:14,208: INFO/MainProcess] Task tasks.get_number[14537419-8710-4b32-bb13-6c884ff22dca] succeeded in 2.0140742670046166s: 10
[2020-01-26 19:35:14,209: INFO/MainProcess] Task tasks.get_number[db7838f5-3543-414c-9816-7df62b13b65d] succeeded in 2.03493124502711s: 6
[2020-01-26 19:35:14,225: INFO/MainProcess] Task tasks.get_number[52f163d4-7d75-493a-a3ac-65122691b078] succeeded in 2.0403319080360234s: 9
[2020-01-26 19:35:14,225: INFO/MainProcess] Received task: tasks.sum_numbers[043e87a0-4963-468a-9f17-7ffe93127fcd]
[2020-01-26 19:35:14,227: INFO/MainProcess] Task tasks.sum_numbers[043e87a0-4963-468a-9f17-7ffe93127fcd] succeeded in 0.0006761000258848071s: 33
</code></pre>

<p>Ici les 5 tâches sont bien effectuées en même temps, le workflow aura donc mis <strong>2 secondes</strong>. Et encore je n&rsquo;ai lancé que 5 tâches en parallèle, n&rsquo;hésitez pas à augmenter ce nombre afin de constater par vous-même les résultats. On comprend bien la puissance de Gevent face à des tâches dédiées à de l&rsquo;IO Bound.</p>

<h1 id="conclusion">Conclusion</h1>

<p>Les pool d&rsquo;exécution ne sont pas beaucoup mis en avant dans la documentation Celery, hors comme vous le voyez il s&rsquo;agit d&rsquo;une configuration très simple à mettre en oeuvre afin de bénéficier de meilleurs performances.</p>

<p>N&rsquo;hésitez surtout pas à utiliser les queues pour effectuer le routing de vos tâches IO bound et CPU bound. Les tâches gourmandes en CPU pourront être redirigées vers une queue <strong>cpu</strong> et les tâches gourmandes en IO bound vers une queue <strong>io</strong>.</p>

<p>Il suffira alors de lancer 2 workers avec les bons arguments :</p>

<pre><code>$ celery -A tasks worker -P gevent -c 100 -Q io
$ celery -A tasks worker -P prefork -c 4 -Q cpu
</code></pre>

<p>Vous trouverez plus d&rsquo;info sur les queues <a href="https://docs.celeryproject.org/en/latest/userguide/routing.html">ici</a>.</p>

<p>En espérant que cet article vous ait plus, n&rsquo;hésitez pas à me contacter sur <a href="https://twitter.com/ncrocfer">Twitter</a> si vous avez des questions ou des remarques :)</p>

                    </div>
                    
                </section>
            </div>
            <div class="footer">
    <div class="pure-menu pure-menu-horizontal pure-menu-open">
        <ul>
            <li>Powered by <a class="hugo" href="https://gohugo.io/" target="_blank">hugo</a></li>
        </ul>
    </div>
</div>
<script src="https://ncrocfer.github.io/js/all.min.js"></script>

        </div>
    </div>
</div>


<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-65778407-1', 'auto');
ga('send', 'pageview');

</script>

</body>
</html>
